{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Visualization\n",
    "\n",
    "This notebook provides comprehensive analysis and professional visualizations for your research report.\n",
    "\n",
    "## Objectives\n",
    "1. Aggregate all experimental data\n",
    "2. Generate statistical insights\n",
    "3. Create publication-quality visualizations\n",
    "4. Provide data for report writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from database import HallucinationDB\n",
    "from config import Config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "db = HallucinationDB()\n",
    "\n",
    "# Get all experiments\n",
    "df_experiments = db.get_all_experiments()\n",
    "print(\"Experiments Summary:\")\n",
    "print(df_experiments)\n",
    "\n",
    "# Get overall statistics\n",
    "stats = db.get_statistics()\n",
    "print(f\"\\nTotal experiments: {stats['total_experiments']}\")\n",
    "print(f\"Total tests conducted: {stats['total_tests']}\")\n",
    "\n",
    "print(\"\\nHallucination rates by mitigation strategy:\")\n",
    "print(stats['hallucination_by_strategy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all experimental results into one dataframe\n",
    "all_results = []\n",
    "\n",
    "for idx, exp in df_experiments.iterrows():\n",
    "    exp_id = exp['experiment_id']\n",
    "    df_exp = db.get_experiment_results(exp_id)\n",
    "    all_results.append(df_exp)\n",
    "\n",
    "if all_results:\n",
    "    df_all = pd.concat(all_results, ignore_index=True)\n",
    "    print(f\"\\nTotal data points: {len(df_all)}\")\n",
    "    print(f\"Date range: {df_all['created_at'].min()} to {df_all['created_at'].max()}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No experimental data found. Please run the testing notebooks first.\")\n",
    "    df_all = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overall Hallucination Rates\n",
    "\n",
    "### 1.1 By Mitigation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    # Calculate rates by strategy\n",
    "    strategy_performance = df_all.groupby('mitigation_strategy').agg({\n",
    "        'is_hallucination': ['count', 'sum', 'mean'],\n",
    "        'response_time_ms': 'mean',\n",
    "        'tokens_used': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    strategy_performance.columns = ['Total Tests', 'Hallucinations', 'Hallucination Rate', \n",
    "                                    'Avg Response Time (ms)', 'Avg Tokens']\n",
    "    strategy_performance['Hallucination Rate (%)'] = strategy_performance['Hallucination Rate'] * 100\n",
    "    \n",
    "    print(\"Strategy Performance Metrics:\")\n",
    "    print(strategy_performance)\n",
    "    \n",
    "    # Save to CSV\n",
    "    strategy_performance.to_csv('../results/reports/strategy_performance.csv')\n",
    "    print(\"\\n✓ Saved to results/reports/strategy_performance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Hallucination Rate Comparison\n",
    "if not df_all.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    strategies = strategy_performance.index\n",
    "    rates = strategy_performance['Hallucination Rate (%)'].values\n",
    "    \n",
    "    colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12']\n",
    "    bars = ax.bar(range(len(strategies)), rates, color=colors[:len(strategies)])\n",
    "    \n",
    "    ax.set_xlabel('Mitigation Strategy', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Hallucination Rate (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Hallucination Rate by Mitigation Strategy', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(range(len(strategies)))\n",
    "    ax.set_xticklabels([s.replace('_', ' ').title() for s in strategies], rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/charts/hallucination_rate_by_strategy.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Chart saved to results/charts/hallucination_rate_by_strategy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 By Prompt Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    # Category performance\n",
    "    category_performance = df_all.groupby('prompt_category').agg({\n",
    "        'is_hallucination': ['count', 'sum', 'mean']\n",
    "    }).round(3)\n",
    "    \n",
    "    category_performance.columns = ['Total', 'Hallucinations', 'Rate']\n",
    "    category_performance['Rate (%)'] = category_performance['Rate'] * 100\n",
    "    category_performance = category_performance.sort_values('Rate (%)', ascending=False)\n",
    "    \n",
    "    print(\"Hallucination Rate by Prompt Category:\")\n",
    "    print(category_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Category heatmap by strategy\n",
    "if not df_all.empty:\n",
    "    # Create pivot table\n",
    "    pivot = df_all.pivot_table(\n",
    "        values='is_hallucination',\n",
    "        index='prompt_category',\n",
    "        columns='mitigation_strategy',\n",
    "        aggfunc='mean'\n",
    "    ) * 100\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(pivot, annot=True, fmt='.1f', cmap='RdYlGn_r', \n",
    "                cbar_kws={'label': 'Hallucination Rate (%)'}, ax=ax)\n",
    "    ax.set_title('Hallucination Rate: Category vs Strategy Heatmap', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Mitigation Strategy', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Prompt Category', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/charts/category_strategy_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Chart saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cost-Benefit Analysis\n",
    "\n",
    "### 2.1 Token Usage vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    # Calculate accuracy (inverse of hallucination rate)\n",
    "    strategy_costs = df_all.groupby('mitigation_strategy').agg({\n",
    "        'tokens_used': 'mean',\n",
    "        'is_hallucination': 'mean',\n",
    "        'response_time_ms': 'mean'\n",
    "    })\n",
    "    \n",
    "    strategy_costs['accuracy'] = (1 - strategy_costs['is_hallucination']) * 100\n",
    "    \n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Tokens vs Accuracy\n",
    "    strategies = strategy_costs.index\n",
    "    ax1.scatter(strategy_costs['tokens_used'], strategy_costs['accuracy'], \n",
    "               s=200, alpha=0.6, c=colors[:len(strategies)])\n",
    "    \n",
    "    for idx, strategy in enumerate(strategies):\n",
    "        ax1.annotate(strategy.replace('_', '\\n'), \n",
    "                    (strategy_costs.loc[strategy, 'tokens_used'],\n",
    "                     strategy_costs.loc[strategy, 'accuracy']),\n",
    "                    fontsize=9, ha='center')\n",
    "    \n",
    "    ax1.set_xlabel('Average Tokens Used', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Token Cost vs Accuracy', fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Response Time vs Accuracy\n",
    "    ax2.scatter(strategy_costs['response_time_ms'], strategy_costs['accuracy'],\n",
    "               s=200, alpha=0.6, c=colors[:len(strategies)])\n",
    "    \n",
    "    for idx, strategy in enumerate(strategies):\n",
    "        ax2.annotate(strategy.replace('_', '\\n'),\n",
    "                    (strategy_costs.loc[strategy, 'response_time_ms'],\n",
    "                     strategy_costs.loc[strategy, 'accuracy']),\n",
    "                    fontsize=9, ha='center')\n",
    "    \n",
    "    ax2.set_xlabel('Average Response Time (ms)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Speed vs Accuracy', fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/charts/cost_benefit_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Chart saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Severity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty and 'severity' in df_all.columns:\n",
    "    # Filter only hallucinations\n",
    "    df_hallucinations = df_all[df_all['is_hallucination'] == True]\n",
    "    \n",
    "    if len(df_hallucinations) > 0:\n",
    "        # Severity distribution\n",
    "        severity_dist = df_hallucinations.groupby(['mitigation_strategy', 'severity']).size().unstack(fill_value=0)\n",
    "        \n",
    "        # Plot\n",
    "        ax = severity_dist.plot(kind='bar', stacked=True, figsize=(10, 6),\n",
    "                               color=['#27ae60', '#f39c12', '#e67e22', '#c0392b'])\n",
    "        ax.set_xlabel('Mitigation Strategy', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Number of Hallucinations', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Hallucination Severity Distribution by Strategy', fontsize=14, fontweight='bold')\n",
    "        ax.legend(title='Severity', title_fontsize=11)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results/charts/severity_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"✓ Chart saved\")\n",
    "    else:\n",
    "        print(\"No hallucinations detected to analyze severity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Visualizations (Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    # Interactive scatter: Response time vs Tokens, colored by hallucination\n",
    "    fig = px.scatter(df_all, \n",
    "                    x='tokens_used', \n",
    "                    y='response_time_ms',\n",
    "                    color='is_hallucination',\n",
    "                    facet_col='mitigation_strategy',\n",
    "                    hover_data=['prompt_category', 'severity'],\n",
    "                    title='Response Characteristics by Strategy',\n",
    "                    labels={'tokens_used': 'Tokens Used',\n",
    "                           'response_time_ms': 'Response Time (ms)',\n",
    "                           'is_hallucination': 'Hallucinated'})\n",
    "    \n",
    "    fig.write_html('../results/charts/interactive_scatter.html')\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"✓ Interactive chart saved to results/charts/interactive_scatter.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Summary for Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    # Generate comprehensive report\n",
    "    report = []\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(\"ML HALLUCINATION RESEARCH - STATISTICAL SUMMARY\")\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(f\"\\nTotal Experiments Conducted: {stats['total_experiments']}\")\n",
    "    report.append(f\"Total Tests Performed: {stats['total_tests']}\")\n",
    "    report.append(f\"Data Collection Period: {df_all['created_at'].min()} to {df_all['created_at'].max()}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"MITIGATION STRATEGY EFFECTIVENESS\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    for strategy in strategy_performance.index:\n",
    "        row = strategy_performance.loc[strategy]\n",
    "        report.append(f\"\\n{strategy.upper().replace('_', ' ')}:\")\n",
    "        report.append(f\"  • Total Tests: {int(row['Total Tests'])}\")\n",
    "        report.append(f\"  • Hallucinations Detected: {int(row['Hallucinations'])}\")\n",
    "        report.append(f\"  • Hallucination Rate: {row['Hallucination Rate (%)']}%\")\n",
    "        report.append(f\"  • Avg Response Time: {row['Avg Response Time (ms)']:.0f}ms\")\n",
    "        report.append(f\"  • Avg Token Usage: {row['Avg Tokens']:.0f} tokens\")\n",
    "    \n",
    "    # Calculate improvement over baseline\n",
    "    if 'baseline' in strategy_performance.index:\n",
    "        baseline_rate = strategy_performance.loc['baseline', 'Hallucination Rate (%)']\n",
    "        report.append(\"\\n\" + \"=\"*80)\n",
    "        report.append(\"IMPROVEMENT OVER BASELINE\")\n",
    "        report.append(\"=\"*80)\n",
    "        \n",
    "        for strategy in strategy_performance.index:\n",
    "            if strategy != 'baseline':\n",
    "                rate = strategy_performance.loc[strategy, 'Hallucination Rate (%)']\n",
    "                improvement = baseline_rate - rate\n",
    "                pct_improvement = (improvement / baseline_rate * 100) if baseline_rate > 0 else 0\n",
    "                report.append(f\"\\n{strategy.upper().replace('_', ' ')}:\")\n",
    "                report.append(f\"  • Absolute Reduction: {improvement:.1f} percentage points\")\n",
    "                report.append(f\"  • Relative Improvement: {pct_improvement:.1f}%\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"TOP HALLUCINATION-PRONE CATEGORIES\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    top_categories = category_performance.nlargest(5, 'Rate (%)')\n",
    "    for idx, (cat, row) in enumerate(top_categories.iterrows(), 1):\n",
    "        report.append(f\"\\n{idx}. {cat.replace('_', ' ').title()}\")\n",
    "        report.append(f\"   Rate: {row['Rate (%)']}% ({int(row['Hallucinations'])}/{int(row['Total'])} tests)\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Print and save\n",
    "    report_text = \"\\n\".join(report)\n",
    "    print(report_text)\n",
    "    \n",
    "    with open('../results/reports/statistical_summary.txt', 'w') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    print(\"\\n✓ Report saved to results/reports/statistical_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_all.empty:\n",
    "    # Export complete dataset\n",
    "    df_all.to_csv('../data/exports/complete_dataset.csv', index=False)\n",
    "    print(\"✓ Complete dataset exported to data/exports/complete_dataset.csv\")\n",
    "    \n",
    "    # Export summary tables\n",
    "    strategy_performance.to_csv('../data/exports/strategy_summary.csv')\n",
    "    category_performance.to_csv('../data/exports/category_summary.csv')\n",
    "    \n",
    "    print(\"✓ Summary tables exported\")\n",
    "    print(\"\\nAll data ready for your report!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights for Your Report\n",
    "\n",
    "Use this section to document your findings:\n",
    "\n",
    "### 1. Primary Research Question\n",
    "**Do mitigation strategies effectively reduce LLM hallucinations in cybersecurity contexts?**\n",
    "\n",
    "Your finding:\n",
    "- \n",
    "\n",
    "### 2. Most Effective Strategy\n",
    "- Which strategy performed best?\n",
    "- By how much did it reduce hallucinations?\n",
    "- What were the trade-offs?\n",
    "\n",
    "Your analysis:\n",
    "- \n",
    "\n",
    "### 3. Vulnerability Categories\n",
    "- Which prompt types were most prone to hallucination?\n",
    "- Did this vary by mitigation strategy?\n",
    "\n",
    "Your notes:\n",
    "- \n",
    "\n",
    "### 4. Practical Recommendations\n",
    "- For cybersecurity applications, which strategy would you recommend?\n",
    "- When is each strategy most appropriate?\n",
    "\n",
    "Your recommendations:\n",
    "- \n",
    "\n",
    "### 5. Limitations & Future Work\n",
    "- What are the limitations of this study?\n",
    "- What would you do differently with more resources?\n",
    "\n",
    "Your thoughts:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "db.close()\n",
    "print(\"\\n✓ Analysis complete!\")\n",
    "print(\"\\nAll visualizations and reports are in:\")\n",
    "print(\"  - results/charts/\")\n",
    "print(\"  - results/reports/\")\n",
    "print(\"  - data/exports/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
