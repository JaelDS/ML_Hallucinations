{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unintentional Hallucination Testing\n",
    "\n",
    "This notebook tests **edge cases and scenarios** where hallucinations may occur unintentionally.\n",
    "\n",
    "## Objectives\n",
    "1. Test knowledge boundaries (cutoff dates, obscure topics)\n",
    "2. Identify ambiguous queries that trigger fabrication\n",
    "3. Document statistical claims without sources\n",
    "4. Establish control baseline with well-known facts\n",
    "\n",
    "## Test Categories\n",
    "- Knowledge cutoff issues\n",
    "- Ambiguous/underspecified queries\n",
    "- Obscure but real topics\n",
    "- Statistical/numerical claims\n",
    "- Speculative future questions\n",
    "- Control questions (should NOT hallucinate)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T02:13:35.569940Z",
     "start_time": "2025-11-08T02:13:27.944134Z"
    }
   },
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from agent import HallucinationTestAgent\n",
    "from database import HallucinationDB\n",
    "from test_vectors import HallucinationTestVectors\n",
    "from config import Config\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Components"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Validate API Key\n\nLet's verify the API key is loaded and working before running tests.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\n\n# Load .env file\nenv_path = Path('../.env')\nload_dotenv(dotenv_path=env_path)\n\n# Get API key\napi_key = os.getenv(\"GROQ_API_KEY\")\n\nprint(\"=\"*60)\nprint(\"API KEY VALIDATION\")\nprint(\"=\"*60)\n\n# Check if .env file exists\nif env_path.exists():\n    print(f\"✓ .env file found at: {env_path.absolute()}\")\nelse:\n    print(f\"✗ .env file NOT found at: {env_path.absolute()}\")\n\n# Check if API key is loaded\nif api_key:\n    print(f\"✓ API key loaded from .env\")\n    print(f\"  Key starts with: {api_key[:10]}...\")\n    print(f\"  Key length: {len(api_key)} characters\")\nelse:\n    print(\"✗ API key NOT loaded from .env\")\n    print(\"  Please check your .env file contains GROQ_API_KEY=your_key_here\")\n\n# Test the API key with a simple request\nif api_key:\n    print(\"\\nTesting API key with Groq API...\")\n    try:\n        client = OpenAI(\n            api_key=api_key,\n            base_url=\"https://api.groq.com/openai/v1\"\n        )\n        \n        response = client.chat.completions.create(\n            model='llama-3.1-8b-instant',\n            messages=[{'role': 'user', 'content': 'Say \"API key works!\"'}],\n            max_tokens=10\n        )\n        \n        print(f\"✓ API key is VALID!\")\n        print(f\"  Response: {response.choices[0].message.content}\")\n        print(f\"  Tokens used: {response.usage.total_tokens}\")\n        \n    except Exception as e:\n        print(f\"✗ API key test FAILED!\")\n        print(f\"  Error: {str(e)}\")\n        print(\"\\n  Possible solutions:\")\n        print(\"  1. Get a new API key from https://console.groq.com/keys\")\n        print(\"  2. Update .env file with: GROQ_API_KEY=your_new_key\")\n        print(\"  3. Restart the kernel to reload .env\")\n\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T02:13:47.851149Z",
     "start_time": "2025-11-08T02:13:47.595114Z"
    }
   },
   "source": [
    "# Initialize\n",
    "agent = HallucinationTestAgent()\n",
    "db = HallucinationDB()\n",
    "\n",
    "# Create experiment for unintentional tests\n",
    "unintentional_exp_id = db.create_experiment(\n",
    "    name=\"Unintentional Hallucinations - Baseline\",\n",
    "    mitigation_strategy=\"baseline\",\n",
    "    description=\"Testing edge cases and knowledge boundaries. Unintentional hallucination scenarios.\"\n",
    ")\n",
    "\n",
    "# Create experiment for control tests\n",
    "control_exp_id = db.create_experiment(\n",
    "    name=\"Control Tests - Baseline\",\n",
    "    mitigation_strategy=\"baseline\",\n",
    "    description=\"Well-established facts that should NOT produce hallucinations.\"\n",
    ")\n",
    "\n",
    "print(f\"Unintentional tests experiment ID: {unintentional_exp_id}\")\n",
    "print(f\"Control tests experiment ID: {control_exp_id}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unintentional tests experiment ID: 4\n",
      "Control tests experiment ID: 5\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Vectors"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T02:13:58.095231Z",
     "start_time": "2025-11-08T02:13:58.083357Z"
    }
   },
   "source": "# Get test vectors\nunintentional_vectors = HallucinationTestVectors.get_unintentional_vectors()\ncontrol_vectors = HallucinationTestVectors.get_control_vectors()\n\nprint(f\"Unintentional test vectors: {len(unintentional_vectors)}\")\nprint(f\"Control test vectors: {len(control_vectors)}\")\n\nprint(\"\\nUnintentional test categories:\")\ncategories = {}\nfor vec in unintentional_vectors:\n    cat = vec['category']\n    categories[cat] = categories.get(cat, 0) + 1\n\nfor cat, count in sorted(categories.items()):\n    print(f\"  - {cat}: {count}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Unintentional Hallucination Tests"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T07:53:49.639510Z",
     "start_time": "2025-11-02T07:53:47.172367Z"
    }
   },
   "source": "print(\"Testing edge cases and knowledge boundaries...\\n\")\n\nfor i, vector in enumerate(tqdm(unintentional_vectors, desc=\"Unintentional tests\")):\n    prompt = vector['prompt']\n    \n    # Query model\n    response, metadata = agent.query_baseline(prompt)\n    \n    # Display\n    print(\"\\n\" + \"=\"*80)\n    print(f\"Test {i+1}/{len(unintentional_vectors)}\")\n    print(f\"Category: {vector['category']}\")\n    print(f\"Description: {vector['description']}\")\n    print(f\"\\nPrompt: {prompt}\")\n    print(f\"\\nResponse:\\n{response}\")\n    print(\"=\"*80)\n    \n    # Manual annotation needed for these (expected_hallucination may be None)\n    # For automated run, default to False if None\n    expected = vector.get('expected_hallucination')\n    is_hallucination = False if expected is None else expected\n    \n    # Uncomment for manual review:\n    # annotation = input(\"\\nDid the model hallucinate? (y/n/u for uncertain): \").strip().lower()\n    # is_hallucination = annotation == 'y'\n    \n    # Determine hallucination type\n    hallucination_type = vector['category'] if is_hallucination else 'none'\n    \n    # Log to database\n    db.log_test(\n        experiment_id=unintentional_exp_id,\n        prompt_text=prompt,\n        response_text=response,\n        is_hallucination=is_hallucination,\n        prompt_category=vector['category'],\n        vector_type='unintentional',\n        expected_hallucination=vector.get('expected_hallucination'),\n        hallucination_type=hallucination_type,\n        severity=vector.get('severity', 'low'),\n        description=vector['description'],\n        response_time_ms=metadata.get('response_time_ms', 0),\n        tokens_used=metadata.get('tokens_used', 0)\n    )\n    \n    time.sleep(1)  # Rate limiting\n\nprint(\"\\n✓ Unintentional hallucination tests complete!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Control Tests\n",
    "\n",
    "These are well-established facts. The model should NOT hallucinate on these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing control questions (should NOT hallucinate)...\\n\")\n",
    "\n",
    "for i, vector in enumerate(tqdm(control_vectors, desc=\"Control tests\")):\n",
    "    prompt = vector['prompt']\n",
    "    \n",
    "    # Query model\n",
    "    response, metadata = agent.query_baseline(prompt)\n",
    "    \n",
    "    # Display\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Control Test {i+1}/{len(control_vectors)}\")\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(f\"\\nResponse:\\n{response}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # These should be False (no hallucination expected)\n",
    "    is_hallucination = False\n",
    "    \n",
    "    # Uncomment to verify:\n",
    "    # check = input(\"\\nDid it hallucinate? (y/n): \").strip().lower()\n",
    "    # is_hallucination = check == 'y'\n",
    "    \n",
    "    # Log to database\n",
    "    db.log_test(\n",
    "        experiment_id=control_exp_id,\n",
    "        prompt_text=prompt,\n",
    "        response_text=response,\n",
    "        is_hallucination=is_hallucination,\n",
    "        prompt_category='control',\n",
    "        vector_type='control',\n",
    "        expected_hallucination=False,\n",
    "        hallucination_type='none',\n",
    "        severity='low',\n",
    "        description=vector['description'],\n",
    "        response_time_ms=metadata.get('response_time_ms', 0),\n",
    "        tokens_used=metadata.get('tokens_used', 0)\n",
    "    )\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\n✓ Control tests complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unintentional results\n",
    "df_unintentional = db.get_experiment_results(unintentional_exp_id)\n",
    "\n",
    "print(\"Unintentional Hallucination Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total tests: {len(df_unintentional)}\")\n",
    "print(f\"Hallucinations: {df_unintentional['is_hallucination'].sum()}\")\n",
    "print(f\"Hallucination rate: {df_unintentional['is_hallucination'].mean()*100:.1f}%\")\n",
    "\n",
    "print(\"\\nBy category:\")\n",
    "category_stats = df_unintentional.groupby('prompt_category')['is_hallucination'].agg(['count', 'sum', 'mean'])\n",
    "category_stats.columns = ['Total', 'Hallucinations', 'Rate']\n",
    "print(category_stats.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control results\n",
    "df_control = db.get_experiment_results(control_exp_id)\n",
    "\n",
    "print(\"Control Test Results (should be 0% hallucination)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total tests: {len(df_control)}\")\n",
    "print(f\"Hallucinations: {df_control['is_hallucination'].sum()}\")\n",
    "print(f\"Hallucination rate: {df_control['is_hallucination'].mean()*100:.1f}%\")\n",
    "\n",
    "if df_control['is_hallucination'].sum() > 0:\n",
    "    print(\"\\n⚠️  WARNING: Model hallucinated on control questions!\")\n",
    "    print(\"These are well-known facts. Review the responses.\")\n",
    "else:\n",
    "    print(\"\\n✓ Good: No hallucinations on control questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export both experiments\n",
    "unintentional_path = db.export_to_csv(unintentional_exp_id)\n",
    "control_path = db.export_to_csv(control_exp_id)\n",
    "\n",
    "print(f\"Unintentional results: {unintentional_path}\")\n",
    "print(f\"Control results: {control_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Observations\n",
    "\n",
    "**Document your findings:**\n",
    "\n",
    "1. **Knowledge Boundaries:**\n",
    "   - How does the model handle questions beyond its knowledge cutoff?\n",
    "   - Does it admit uncertainty or fabricate?\n",
    "\n",
    "2. **Ambiguous Queries:**\n",
    "   - Does the model invent specifics for vague questions?\n",
    "   - Does it ask for clarification?\n",
    "\n",
    "3. **Statistical Claims:**\n",
    "   - Does it cite specific numbers without sources?\n",
    "   - How confident does it sound?\n",
    "\n",
    "4. **Control Performance:**\n",
    "   - Did any well-known facts get incorrect responses?\n",
    "\n",
    "**Your notes:**\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Proceed to **03_comparative_analysis.ipynb** to test how mitigation strategies (RAG, Constitutional AI, Chain-of-Thought) perform on these same prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}